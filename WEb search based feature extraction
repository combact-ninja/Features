import requests
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
import re

# Function to scrape text data from web search results
def scrape_web_search_results(query, num_results=5):
    url = f"https://www.google.com/search?q={query}&num={num_results}"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    search_results = soup.find_all('div', class_='BNeawe vvjwJb AP7Wnd')
    search_text = ' '.join([result.get_text() for result in search_results])
    return search_text

# Function to preprocess text
def preprocess_text(text):
    # Remove special characters and numbers
    text = re.sub('[^a-zA-Z]', ' ', text)
    # Convert to lowercase
    text = text.lower()
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    words = text.split()
    filtered_words = [word for word in words if word not in stop_words]
    text = ' '.join(filtered_words)
    return text

# Example query for web search
query = "Python"

# Scrape web search results
search_text = scrape_web_search_results(query)

# Preprocess the text
clean_text = preprocess_text(query)

# Feature extraction using CountVectorizer
vectorizer = CountVectorizer(max_features=1000)
X = vectorizer.fit_transform([clean_text]).toarray()
features = vectorizer.get_feature_names_out()

print("Features extracted:")
print(features)


Explanation:

    The scrape_web_search_results function takes a query and number of results as input, constructs a Google search URL, and scrapes the text content from the search results using BeautifulSoup and requests libraries.

    The preprocess_text function preprocesses the scraped text by removing special characters, numbers, converting to lowercase, and removing stopwords using NLTK.

    The query variable contains the search query for which you want to extract features from the web search results.

    The search_text variable stores the scraped text from the web search results.

    The clean_text variable contains the preprocessed text ready for feature extraction.

    The CountVectorizer is used to extract features from the preprocessed text, limiting the number of features to 1000.

    The X variable stores the extracted features as a matrix, and features contains the feature names extracted by the CountVectorizer.
